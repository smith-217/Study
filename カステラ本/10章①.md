---
marp: true
---

<!-- $size: 16:9 -->
<!-- page_number: true -->
<!-- paginate: true -->
<!-- _class: title-->

# カステラ本10章（10.1〜10.8）


---
# 10.1 ブースティング法

- 大量の弱分類器の出力を組み合わせて強力な出力を得る
- 最近提案された学習法の中で最も強力なものの一つ

---
## アダブーストM1
- 2クラス分類問題におけるブースティング
- ブースティングの最も一般的なアプローチ
- 全ての弱分類器 $G_m(x)$ による予測を
重み付き多数決により組み合わせて
最終的な予測値 $G(x)$ を算出

$$G(x)=sign(\sum_{m=1}^M\alpha_mG_m(x))$$

$\qquad sign()$：$\lbrace -1, 1\rbrace$の予測結果を出力
$\qquad \alpha_m$：$G_m(x)$ の貢献度

$\qquad$※より正確な分類器に高い貢献度を付与


![bg right:43.45% w:600 h:450](スクリーンショット%202020-12-15%2023.03.02.png)

---
## アダブーストM1のアルゴリズム(10.1)

1. 観測値に付加する重みを初期化：$w_i=\frac{1}{N}(i=1,2,...,N)$
2. $m=1,...M$に対して以下を行う
(a) 重み $w_i$ を用いて分類器 $G_m(x)$ を学習データに当てはめる
(b) (a)の結果から得られる重み付き誤分類率を計算：$err_m = \frac{\sum_{i=1}^Nw_iI(y_i\not ={G_m(x_i)})}{\sum_{i=1}^Nw_i}$
(c) $G_m(x)$に対する重み（影響力）の計算： $\alpha_m=log(\frac{1-err_m}{err_m})$ 
(d) 観測値の重み $w_i$を以下の通り更新
$$w_i\gets w_i*exp[\alpha_m \times I(y_i \not ={G_m(x)})] (i=1,2,...,N)$$
3. 予測値 $G(x)=sign[\sum_{m=1}^M \alpha_mG_m(x)]$ を出力

---
## 誤分類率の精度向上

- 特徴量 $X_1,...,X_{10}$
$$\qquad Y =  \begin{cases}
  1 & \sum_{j=1}^{10} X_j^2 > \chi_{10}^2 (0.5) = 9.34\\
  -1 & その他
\end{cases}$$
- **非常に単純な弱分類器をブースティングすることで、予測誤差は単独の大きな分類木に比べて大幅に改善されている**

![bg right:45% w:540 h:420](スクリーンショット%202020-12-15%2023.03.14.png)

---
## 10章の展開(前半部分)
- 10.2〜10.4
  - アダブーストと加法的モデルの関係
  - 損失関数の導入
- 10.5
  - 損失関数（指数損失）の意味合い
- 10.6
  - 回帰や分類のためのロバストな損失関数について
- 10.7, 10.9
  - ブースティングのデータマイニング応用
  - 決定木が理想的な学習器であることについて
- 10.8
  - 手法の応用例

---
# 10.2 ブースティングによる加法的モデル当てはめ
### ブースティングのすごいところ
- 基底関数 $G_m(x)$ を用いた加法的展開の当てはめをしつつ、その計算コストを改善
  - モデルの当てはめにおいて計算量の大きい数値最適化手法が必要となる損失関数の計算を一部簡略化できる可能性がある。

---
# 10.3 前向き段階的加法的モデリング
- 既に追加された基底関数のパラメータや係数を調整することなく、
新たな基底関数を展開に順次追加していく。
- $m$ 回目の繰り返しにおいて、現在の展開 $f_{m-1}(x)$ に追加するための、
最適な基底関数 $b(x;\gamma_m)$ と係数 $\beta_m$ を求めることで $f_m(x)$ を生成する。
- 以前に追加された項を修正しない形で上記プロセスを繰り返す。

---
## 前向き段階的加法的モデリングのアルゴリズム(10.2)

1. 初期化：$f_0(x) = 0$
2. $m=1, ..., M$ に対して以下を行う
(a) 次の計算をする
$\qquad \quad (\beta_m, \gamma_m) = \argmin\limits_{\beta, \gamma}\sum_{i=1}^N L(y_i, f_{m-1}(x_i)+\beta b(x_i;\gamma))$
(b) 展開を更新する
$$f_m(x)=f_{m-1}(x)+\beta_m b(x;\gamma_m)$$

---
# 10.4 指数損失とアダブースト

- アダブーストM1は、損失関数 

$$L(y,f(x))=exp(-yf(x)) \qquad　(10.8)$$

$\quad$ を用いた**前向き段階的加法的モデリング**とみなすことができる。

---
## モデルの当てはめ (1)

- アルゴリズム(10.2) 2より、
$$(\beta_m, G_m) = \argmin_{\beta, G}\sum_{i=1}^N w_i^{(m)}exp(-\beta y_iG(x_i)) \qquad (10.9)$$
$\qquad$  ※ $w_i^{(m)} = exp(-y_if_{m-1}(x_i))$ 
$\qquad \qquad \quad$ $\beta$ にも $G(x)$ にも依存しない各観測値に対する重み
$\qquad \qquad \quad$ $f_{m-1}$ に依存するため、$w_i^{(m)}$ は繰り返し回数 $m$ とともに変化する。

---
## モデルの当てはめ (2)

- 任意の $\beta$ に対する $G_m$
  - 予測値 $y$ の重み付き誤差率を最小化する分類器
$$G_m = \argmin_G\sum_{i=1}^Nw_i^{(m)}I(y_i \not ={G(x_i)}) \qquad (10.10)$$
- $\beta_m$ の推定値 ($G_m$を式(10.9)に代入し、$\beta$について解く)
$$\beta_m = \frac{1}{2}log\frac{1-err_m}{err_m}$$
- 最小化重み付き誤差率：$err_m = \frac{\sum_{i=1}^Nw_i^{(m)}I(y_i\not ={G_m(x_i)})}{\sum_{i=1}^Nw_i^{(m)}}$

---
## モデルの当てはめ (3)
- $G_m$ が 予測値 $y$ の重み付き誤差率を最小化していることは、以下のように表現できる。
$$e^{-\beta}\sum_{y_i=G(x_i)} w_i^{(m)} + e^\beta\sum_{y_i\not ={G(x_i)}}w_i^{(m)}$$
$$⇄ (e^\beta-e^{-\beta})\sum_{i=1}^Nw_i^{(m)}I(y_i\not ={G(x_i)})+e^{-\beta}\sum_{i=1}^Nw_i^{(m)}\qquad (10.11)$$
- したがって、アルゴリズム(10.1)における

> (a) 重み $w_i$ を用いて分類器 $G_m(x)$ を学習データに当てはめる

$\quad$ は、式(10.10)と(10.11)における最小化の近似的解法と見ることができる。

---
## モデルの更新 (1)
- 近似式
$$f_m(x) = f_{m-1}(x)+\beta_mG_m(x)$$
- 重みの更新
$$w_i^{(m+1)} = w_i^{(m)} e^{-\beta_my_iG_m(x_i)} \qquad (10.14)$$

---
## モデルの更新 (2)
- $-y_iG_m(x_i) = 2・I(y_i\not ={G_m(x_i)})-1$ により式(10.14)を変換すると
$$w_i^{(m+1)} = w_i^{(m)}e^{2\beta_mI(y_i\not ={G_m(x_i)})}e^{-\beta_m}$$
- 分類器（$G_m$）に対する重み（影響力）の計算（アルゴリズム10.1 2(c)）
$$2\beta_m = log\frac{1-err_m}{err_m} = \alpha_m$$
- 重みを更新
$$w_i^{(m+1)} = w_i^{(m)}e^{\alpha_mI(y_i\not ={G_m(x_i)})}e^{-\beta_m} \qquad (10.15)$$

---
## モデルの更新 (3)
- 式(10.15)は、アルゴリズム(10.1) 2(d)
> $$w_i\gets w_i*exp[\alpha_m \times I(y_i \not ={G_m(x)})] (i=1,2,...,N)$$
と等価といえる
（$e^{-\beta_m}$ は、全ての重みに同じ値をかけるため、効果なし） 

---
## 汎化性能への寄与

- 訓練集合の誤分類率が0付近で維持されている間も指数損失が減少し続け、テスト誤分類率が改善し続ける。

![bg right:40% w:450 h:380](スクリーンショット%202020-12-15%2023.03.29.png)

---
# 10.5
## なぜ指数損失関数か
- 加法的モデリングの観点での指数損失の魅力
  - 計算効率性
  - 統計的性質における重要性

---
## 指数損失の統計的重要性
- 指数損失が何を推定するのか
  - 母集団での最小化を考える。
$$f^\ast(x) = \argmin_{f(x)}E_{Y|x}(e^{-Yf(x)})=\frac{1}{2}log\frac{P_r(Y=1|x)}{P_r(Y=-1|x)}\qquad (10.16)$$
- アダブーストにより得られる加法的展開は、$P(Y=1|x)$ の対数オッズの2分の1を
推定している。
  - 分類器における符号関数の妥当性を示す。

---
# 10.6 損失関数とロバスト性
## 分類のためのロバスト損失関数
- 指数損失： 
> $L(y, f(x)) = exp(-yf(x)) \qquad(10.8)$
- 逸脱度：
> $-l(y, f(x)) = log(1+e^{-2Yf(x)})\qquad(10.18)$
- マージン = $-yf(x)$
  - 分類問題において、回帰における残差 $y-f(x)$ と同じ役割
  - 両者の規準は、このマージンの単調減少関数という共通性がある。

---
## 分類のためのロバスト損失関数
- 分類問題におけるマージンの振る舞い
  - 分類器 $G(x) = sign[f(x)]\qquad\isin\lbrace-1, 1\rbrace$
    - $y_if(x_i)>0$ で正しく分類（$y_i>0,f(x)>0 / y_i<0, f(x)<0$）
    - $y_if(x_i)<0$ で誤分類（$y_i>0,f(x)<0 / y_i<0, f(x)>0$）
    - 決定境界：$f(x)=0$
  - 分類アルゴリズムの目的
    - 負のマージンに対して罰則を与える
    - **正のマージンは既に正しく分類できているので、罰則はいらない**

---
## 各損失関数の特徴比較
- 指数 / 逸脱度：
  - 罰則の与え方の度合い
    - 指数は大きな負のマージンに
    強い影響を受ける。
    - 逸脱度の方が全てのデータに
    均等に影響を広げられるため、
    よりロバストになる。
![bg right:40% w:540 h:380](スクリーンショット%202020-12-15%2023.03.39.png)

---
## 各損失関数の特徴比較
- 二乗誤差：
  - 一部領域において精度が高い
$$\qquad\begin{aligned}f^\ast(x)&=\argmin_{f(x)}E_{Y|x}(Y-f(x))^2 \\
&= E(Y|x) = 2P_r(Y=1|x)-1
\end{aligned}$$

- ヒンジ損失
  - 正のマージンに対する罰則を0にできる
$$\qquad L(y,f(x)) = \begin{cases}
   0 &\text{if } \quad yf(x)>1 \\
   線形 &\text{if } \quad yf(x)<-1
\end{cases}$$


![bg right:38% w:540 h:380](スクリーンショット%202020-12-15%2023.03.39.png)

---
## 各損失関数の特徴比較
- フーバー的2乗ヒンジ損失 (図12.4)
  - 逸脱度、2乗誤差、ヒンジ損失の
  良い部分を組み合わせる。
![bg right:45% w:600 h:420](スクリーンショット%202020-12-15%2023.31.04.png)

---
## 多クラス分類
- 応答 $Y$：$\qquad \mathcal{G} = \lbrace\mathcal{G_1},...,\mathcal{G_k}\rbrace$
- クラス所属確率：$\qquad p_k(x)=\Pr(Y=\mathcal{G}|x),\quad k=1,...,K$
- クラス所属確率のロジスティックモデル：$\qquad p_k(x) = \frac{e^{f_k(x)}}{\sum_{l=1}^K e^{f_l(x)}}$
- $\quad 0 \le p_k(x) \le 1 \quad$ で $\quad \sum_{k=1}^K p_k(x) = 1$
- $f_k(x)$ には冗長性があり、対称性を保つことが望ましいため、
次の拘束条件を課す：$\qquad \sum_{k=1}^Kf_k(x) = 0$

---
## 多クラス分類

- クラス推定：ベイズ分類器
$$G(x) = \mathcal{G_k}\quad where \quad k = \argmax_k p_l(x)$$
- 損失関数も多クラスに自然に拡張できる
  - 逸脱度：
$$\begin{aligned}
L(y, p(x)) &= 
  - \sum_{k=1}^K I(y = \mathcal{G_k})logp_k(x) \\
  &= - \sum_{k=1}^K I(y=\mathcal{G_k})f_k(x)+log(\sum_{l=1}^K e^{f_l(x)})
\end{aligned}$$
---
## 回帰のためのロバスト損失関数
損失関数|式|母集団上の解|有限サンプル上
:-:|:-:|:-|:-:|
2乗誤差損失|$L(y,f(x))=(y-f(X))^2$|$f(x)=E(Y \lvert x)$|裾の長い誤差分布や外れ値が存在する場合にロバスト性が低下|
絶対値損失|$L(y,f(x))=\lvert y-f(X)\rvert$|$f(x)=median(Y\lvert x)$|裾野長い誤差分布や外れ値に対してロバスト|

---
## 回帰のためのロバスト損失関数
### 絶対値誤差損失の特徴を拡張
- **フーバー損失**
$$L(y,f(x)) = \begin{cases}[y-f(x)]^2 & for \quad \lvert y-f(x) \rvert \le \delta \\2\delta \lvert y-f(x) \rvert - \delta^2 &  \quad otherwise\end{cases}$$

![bg right:40% w:450 h:380](スクリーンショット%202020-12-15%2023.03.49.png)

---
## ロバスト性まとめ
- ロバスト性に関しては、
  - 回帰における二乗誤差損失
  - 分類における指数損失
  のように、統計学的に最良とは言えない規準もある
- しかし、これらは段階的加法的モデリングにおける
**単純にモデルを当てはめられるという**簡潔なアルゴリズムを提示できる
（これをよりロバストな規準に単純に置き換えることはできない）


---
# 10.7 
## データマイニングの「万能」手法

- ここまでに紹介してきた予測学習法は、
特定の状況のもとで最良の性能を出す
- しかし、与えられた問題に対して
どれが最良かを事前に予測できることは
ほとんどない
![bg right:40% w:500 h:420](スクリーンショット%202020-12-15%2023.04.02.png)
---
## ビジネス領域でのデータマイニングあるある
- 与えられるデータ量や変数量が非常に多くなる
- データが乱雑
  - データ型が混合
  - 欠損値の存在
  - 予測変数と応答変数の分布が歪んでいることが多い
  - 外れ値を含むことが多い
  - 予測変数間で大きくスケールが異なる

---
## ビジネス領域でのデータマイニングあるある
- 予測変数のうち、一部しか予測の役に立っていないことがある
- 特徴量を選択するための、対象分野についての明確な知識が得られない
- データマイニングでは、一般的に説明性の高いモデルが求められる
  - 説明変数と予測値の関係に関する定性的理解を促す情報がある方が良い
---
## 「万能手法」**決定木**
- 比較的高速に説明性の高いモデルを構築するのに有効
  - 変数型の混合、欠損値の利用に適する
  - 各説明変数の変換に対して不変
  - 外れ値の影響を受けない
  - 木を構成する各段階で、内部的な特徴量選択を行っている
- 決定木をブースティングすることで、決定木の致命的欠点である**予測精度**を大幅に改善できる
- さらに、勾配ブースティングモデルを採用することで、ブースティングにおけるスピードや説明性、アダブーストで問題となっていたロバスト性などに関する
欠点を緩和できる

---
# 10.8
## 例：スパムデータ
- 9.1.2項で用いたのと同じテストデータに各手法を適用し、誤差率を比較

手法|テスト誤差率|
:-:|:-:|
**勾配ブースティング**|**4.5%**|
加法的ロジスティック回帰|5.5%|
CART|8.7%|
MARS|5.5%|

---
## 例：スパムデータ

- 予測変数の相対的重要度
- ここでモデリングされている量は
$$f(x) = log\frac{\Pr(spam|x)}{\Pr(email|x)}$$
- 最もスパムと関連の強い予測変数
  - `!`, `remove`, `$` ,`hp`
![bg right:45% w:480 h:640](スクリーンショット%202020-12-15%2023.04.19.png)

---
## 例：スパムデータ
- スパムとの関連性
  - 正の関連：`!`/ `remove`
  - 負の関連：`edu` / `hp`
- これらの特定の依存性は、手法によらず本質的に一定であると思われる。
  - それぞれの依存性が、
  加法的ロジスティック回帰モデルにより得られる関数と同様の傾向
  （図9.1）

![bg right:45% w:500 h:420](スクリーンショット%202020-12-15%2023.04.28.png)

---
## 例：スパムデータ
- これらの変数における相互作用の可能性
- `hp` の頻度が低下するにつれて、 `!` との
関数的関係が強くなっている。

![bg right:40% w:450 h:380](スクリーンショット%202020-12-15%2023.04.35.png)